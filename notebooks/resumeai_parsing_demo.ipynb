{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2490ab13-1dcd-4dd3-80f1-2cf1c477fc75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIzaSyAOHankpIg1RveQvGEcp99IdZ-J_y33RSs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "print(os.getenv(\"GEMINI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a53ad24-9a4e-430f-95f9-46aacac43bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/Shared/Main/CMU/Assignments/Intro to AI/ResumeAi\n",
      "✓ Successfully imported JobParser and ResumeParser!\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Set project root to parent directory of notebooks/\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "print(\"Project root:\", PROJECT_ROOT)\n",
    "\n",
    "# Make sure src/ is importable\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from src.parsers.job_parser import JobParser\n",
    "from src.parsers.resume_parser import ResumeParser\n",
    "\n",
    "print(\"✓ Successfully imported JobParser and ResumeParser!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9f5167b-bee0-4cf5-b268-a2eed9a3ae83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Shared/Main/CMU/Assignments/Intro to AI/ResumeAi/tests/test_job_parser/sample_job_description.txt True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job validation issues: ['education_requirement_not_specified']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Parsed Job Description ===\n",
      "job_id=None title='senior software test engineer, embedded systems, silicon' company='google' role=None description=\"at google, our philosophy is build it, break it and then rebuild it better. that thinking is at the core of how we approach testing at google. unlike roles with similar names at the other companies, test engineers at google aren't manual testers -- you write scripts to automate testing and create tools so developers can test their own code. as a test engineer, you navigate google's massive codebase, identify weak spots and constantly design better and creative ways to break software and identify potential problems. you'll have a huge impact on the quality of google's growing suite of products and services.\\n\\nyou use your knowledge of testing and testability to influence better software design, promote proper engineering practice, bug prevention strategies, testability, accessibility, privacy, and other advanced quality concepts across products.\\n\\ngoogle's mission is to organize the world's information and make it universally accessible and useful. our team combines the best of google ai, software, and hardware to create radically helpful experiences. we research, design, and develop new technologies and hardware to make computing faster, seamless, and more powerful. we aim to make people's lives better through technology.\\n\\nthe us base salary range for this full-time position is $144,000-$211,000 + bonus + equity + benefits. our salary ranges are determined by role, level, and location. within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. your recruiter can share more about the specific salary range for your preferred location during the hiring process.\\n\\nplease note that the compensation details listed in us role postings reflect the base salary only, and do not include bonus, equity, or benefits. learn more about benefits at google.\" responsibilities=['deliver exceptional software quality for one or more ips within silicon software.', 'create and implement test strategies by working with development teams to identify risk areas and fill the testing gaps.', 'drive test automation using existing test frameworks and work with the engineering productivity team to enhance and develop new test frameworks based on test requirements.', 'manage product and engineering excellence as a core value within test engineering and with our associated development partners.', 'triage and analyze test results and incoming feedback to identify areas for improvement.'] required_skills=RequiredSkills(must_have=['coding', 'developing test methodologies', 'writing test plans', 'creating test cases', 'debugging', 'hardware testing', 'embedded testing', 'automation', 'testing embedded software on soc on linux', 'testing embedded software on soc on android', 'testing embedded software on soc on real-time operating system (rtos)', 'hardware architecture', 'board schematics', 'protocols', 'standards'], nice_to_have=['working with prototype devices', 'android application development', 'linux kernel driver test automation', 'framework development', 'java', 'c/c++', 'jni', 'python', 'test engineering', 'well tested code']) required_experience=ExperienceRequirement(min_years=5.0, max_years=None, preferred_years=None) education_requirement=EducationRequirement(min_level='bachelor', preferred_level=None, field=None) location_requirement=LocationRequirement(location='mountain view, ca, usa', remote_allowed=False, hybrid=False) salary_range='$144,000-$211,000' benefits=['bonus', 'equity', 'benefits'] company_name=None company_info={}\n"
     ]
    }
   ],
   "source": [
    "job_file = PROJECT_ROOT / \"tests\" / \"test_job_parser\" / \"sample_job_description.txt\"\n",
    "print(job_file, job_file.exists())\n",
    "\n",
    "job_parser = JobParser()\n",
    "parsed_job = job_parser.parse_from_file(str(job_file))\n",
    "\n",
    "print(\"=== Parsed Job Description ===\")\n",
    "print(parsed_job)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7ade88a-5be1-4f1c-ae39-0a0a6758d8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Shared/Main/CMU/Assignments/Intro to AI/ResumeAi/tests/test_parser/test_resume/Shivendra_Resume.docx True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resume validation issues: ['education_level_unknown']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Parsed Resume ===\n",
      "personal_info=PersonalInfo(name='shivendra bhonsle', email='shivendra@cmu.edu', phone='+1 (412) 954-8076', location=Location(city='unknown', country='unknown', remote_preference='unknown'), summary='unknown', linkedin='https://www.linkedin.com/in/shivendrabhonsle/', github=None) experience=[Experience(company='gemini', company_info=CompanyInfo(industry='unknown', size='unknown'), title='software engineer intern', level='unknown', employment_type='intern', dates=DateRange(start='june 2025', end='august 2025', duration='3 months'), responsibilities=['built a real-time credit card operations dashboard (next.js, scala, postgresql) that improved fraud visibility and transaction monitoring, enabling 20+ internal stakeholders to track user states in real time.', 'implemented a bulk email dispatch system with unc sink service over grpc, enabling secure communication with capacity for 50k+ daily emails directly from the admin dashboard', 'developed a scala-based ato log monitoring tool analyzing millions of user events for anomalies; adopted by trust & security team (10+ analysts) to accelerate incident response by 30%', 'created an on-chain wallet verification system in a 3-day hackathon, enabling gemini users to access decentralized apps with pre-verified identities; solution recognized internally for enhancing web3 security'], technical_environment=TechnicalEnvironment(technologies=['next.js', 'scala', 'postgresql', 'grpc'], methodologies=[], tools=[])), Experience(company='eq technologic', company_info=CompanyInfo(industry='unknown', size='unknown'), title='software engineer', level='unknown', employment_type='full-time', dates=DateRange(start='august 2023', end='july 2024', duration='1 year'), responsibilities=['designed and implemented a java connector for ansys stk using stk connect api, integrating simulation workflows into enterprise systems and reducing integration time by 60% for 5+ teams', 'developed 100+ junit test cases to validate crud operations and connector performance, improving code coverage by 35% and reducing integration defects reported in qa by 20%', 'engineered siemens teamcenter plm connectors automating data ingestion from 5+ legacy systems, reducing manual mapping efforts by 70% and streamlining enterprise data migration'], technical_environment=TechnicalEnvironment(technologies=['java', 'junit'], methodologies=[], tools=['junit'])), Experience(company='eq technologic', company_info=CompanyInfo(industry='unknown', size='unknown'), title='software engineer intern', level='unknown', employment_type='intern', dates=DateRange(start='january 2023', end='may 2023', duration='5 months'), responsibilities=['created a vulnerability scanning utility (spring boot, apache poi, maven) parsing 200+ plugin dependencies daily, generating automated excel reports and reducing manual scanning effort by 80%', 'collaborated with senior engineers to integrate the utility into devsecops pipelines, enabling early detection of 50+ critical vulnerabilities per release cycle and strengthening product security posture'], technical_environment=TechnicalEnvironment(technologies=['java', 'spring boot', 'apache poi', 'maven'], methodologies=['devsecops'], tools=[])), Experience(company='algoanalytics', company_info=CompanyInfo(industry='unknown', size='unknown'), title='cloud engineer intern', level='unknown', employment_type='intern', dates=DateRange(start='september 2022', end='march 2023', duration='7 months'), responsibilities=['led migration of a stock market analysis mlops platform from aws to azure, deploying 6 microservices via aks, acr, cosmos db, and blob storage, improving scalability and cutting infra costs by 25%', 'built ci/cd pipelines with github actions and automated container executions via cron jobs aligned with stock market trading hours, ensuring 99.9% uptime for real-time analytics workloads'], technical_environment=TechnicalEnvironment(technologies=['aws', 'azure', 'cosmos db', 'blob storage', 'github actions'], methodologies=['mlops', 'cicd'], tools=['aks', 'acr']))] education=[Education(degree=Degree(level='master', field='information systems management', major='information systems management'), institution=Institution(name='carnegie mellon university', location='pittsburgh, united states', accreditation='unknown'), dates=DateRange(start='august 2024', end='december 2025', duration='1 year 5 months'), achievements=Achievements(gpa=3.66, honors='unknown', relevant_coursework=['cloud computing', 'distributed systems', 'machine learning in production'])), Education(degree=Degree(level='bachelor', field='information technology', major='information technology'), institution=Institution(name='pune institute of computer technology', location='pune, india', accreditation='unknown'), dates=DateRange(start='august 2019', end='july 2023', duration='4 years'), achievements=Achievements(gpa=3.94, honors='unknown', relevant_coursework=['distributed systems', 'machine learning', 'devops', 'deep learning']))] skills=Skills(technical=TechnicalSkills(programming_languages=[Skill(name='java', level='unknown'), Skill(name='c/c++', level='unknown'), Skill(name='python', level='unknown'), Skill(name='go', level='unknown'), Skill(name='scala', level='unknown')], frameworks=[Skill(name='maven', level='unknown'), Skill(name='spring boot', level='unknown'), Skill(name='django', level='unknown'), Skill(name='nodejs', level='unknown'), Skill(name='next.js', level='unknown')], databases=[Skill(name='mysql', level='unknown'), Skill(name='firebase', level='unknown'), Skill(name='cosmos db', level='unknown'), Skill(name='mongodb', level='unknown')], cloud=[Skill(name='azure cloud', level='unknown'), Skill(name='aws', level='unknown'), Skill(name='gcp', level='unknown')], tools=[Skill(name='git', level='unknown'), Skill(name='bitbucket', level='unknown'), Skill(name='jira', level='unknown'), Skill(name='jenkins', level='unknown'), Skill(name='kubernetes', level='unknown'), Skill(name='docker', level='unknown'), Skill(name='hadoop', level='unknown'), Skill(name='spark', level='unknown'), Skill(name='linux', level='unknown'), Skill(name='apache poi', level='unknown'), Skill(name='junit', level='unknown'), Skill(name='github actions', level='unknown'), Skill(name='aks', level='unknown'), Skill(name='acr', level='unknown'), Skill(name='blob storage', level='unknown'), Skill(name='kafka', level='unknown'), Skill(name='redis', level='unknown'), Skill(name='databricks', level='unknown'), Skill(name='helm', level='unknown'), Skill(name='neo4j', level='unknown')]), languages=[]) projects=[Project(name='high performance movie recommendation system', description='designed and deployed a scalable ai-powered recommendation system integrating content-based and collaborative ml models, achieving significant gains in recommendation precision through hybrid model optimization.\\nbuilt distributed data pipelines and caching infrastructure using kafka, mysql, and redis to support real-time ingestion, storage, and low-latency inference, mirroring production-scale cloud ai architectures.\\ncontainerized and deployed the service on aws ec2 with modular apis, enabling fault-tolerant model serving, efficient resource utilization, and automated retraining workflows for continuous learning.', technologies=['kafka', 'mysql', 'redis', 'aws ec2'], role='unknown', url=None, impact='unknown'), Project(name='cloud-native high-throughput microservices platform', description='architected and deployed a cost-optimized microservices platform on aws with 3 core services (blockchain validator, qr auth, twitter recommender) in go/scala/grpc, sustaining 80k+ rps within a strict $1.28/hr budget, demonstrating scalability under real-world constraints\\nprocessed 1tb+ twitter data using databricks spark etl and optimized amazon aurora mysql schema, enabling real-time recommendations with query latency reduced by 40%\\ndesigned fault-tolerant infrastructure with alb, kubernetes managed node groups, and helm ci/cd pipelines, enabling auto-scaling to 1m+ concurrent requests with minimal latency and 99.99% uptime under peak load', technologies=['aws', 'go', 'scala', 'grpc', 'databricks', 'spark', 'mysql', 'alb', 'kubernetes', 'helm'], role='unknown', url=None, impact='unknown'), Project(name='reddit book: distributed social network with heterogeneous datastores', description='engineered a full-stack social network prototype supporting reddit-style comment timelines using a polyglot backend architecture: mysql (relational), neo4j (graph), mongodb (document), and redis (key-value)\\ndesigned custom schemas and implemented 4 concurrent query types via java servlets, reducing query response times by 35% for friend-of-friend and comment search operations\\noptimized mongodb indexing and redis data structures (hashes/lists), benchmarking performance across 1.4m+ reddit records to achieve sub-50ms query latency for real-time social feeds', technologies=['mysql', 'neo4j', 'mongodb', 'redis', 'java servlets'], role='unknown', url=None, impact='unknown')] certifications=''\n"
     ]
    }
   ],
   "source": [
    "resume_file = PROJECT_ROOT / \"tests\" / \"test_parser\" / \"test_resume\"/\"Shivendra_Resume.docx\"\n",
    "print(resume_file, resume_file.exists())\n",
    "\n",
    "resume_parser = ResumeParser()\n",
    "parsed_resume = resume_parser.parse_from_docx(str(resume_file))\n",
    "\n",
    "print(\"=== Parsed Resume ===\")\n",
    "print(parsed_resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d13fda6-130f-4750-8429-20530e86f094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Job Features ===\n",
      "required_skills: ['automation', 'board schematics', 'coding', 'creating test cases', 'debugging', 'developing test methodologies', 'embedded testing', 'hardware architecture', 'hardware testing', 'protocols', 'standards', 'testing embedded software on soc on android', 'testing embedded software on soc on linux', 'testing embedded software on soc on real-time operating system (rtos)', 'writing test plans']\n",
      "nice_to_have_skills: ['android application development', 'c/c++', 'framework development', 'java', 'jni', 'linux kernel driver test automation', 'python', 'test engineering', 'well tested code', 'working with prototype devices']\n",
      "all_skills: ['android application development', 'automation', 'board schematics', 'c/c++', 'coding', 'creating test cases', 'debugging', 'developing test methodologies', 'embedded testing', 'framework development', 'hardware architecture', 'hardware testing', 'java', 'jni', 'linux kernel driver test automation', 'protocols', 'python', 'standards', 'test engineering', 'testing embedded software on soc on android', 'testing embedded software on soc on linux', 'testing embedded software on soc on real-time operating system (rtos)', 'well tested code', 'working with prototype devices', 'writing test plans']\n",
      "num_required_skills: 15\n",
      "required_years: 5.0\n",
      "min_years: 5.0\n",
      "max_years: None\n",
      "required_education_level: 0\n",
      "preferred_education_level: 0\n",
      "required_field: None\n",
      "location: mountain view, ca, usa\n",
      "location_city: mountain view\n",
      "location_country: usa\n",
      "remote_allowed: False\n",
      "hybrid: False\n",
      "description_text: at google, our philosophy is build it, break it and then rebuild it better. that thinking is at the core of how we approach testing at google. unlike roles with similar names at the other companies, test engineers at google aren't manual testers -- you write scripts to automate testing and create tools so developers can test their own code. as a test engineer, you navigate google's massive codebase, identify weak spots and constantly design better and creative ways to break software and identify potential problems. you'll have a huge impact on the quality of google's growing suite of products and services.\n",
      "\n",
      "you use your knowledge of testing and testability to influence better software design, promote proper engineering practice, bug prevention strategies, testability, accessibility, privacy, and other advanced quality concepts across products.\n",
      "\n",
      "google's mission is to organize the world's information and make it universally accessible and useful. our team combines the best of google ai, software, and hardware to create radically helpful experiences. we research, design, and develop new technologies and hardware to make computing faster, seamless, and more powerful. we aim to make people's lives better through technology.\n",
      "\n",
      "the us base salary range for this full-time position is $144,000-$211,000 + bonus + equity + benefits. our salary ranges are determined by role, level, and location. within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. your recruiter can share more about the specific salary range for your preferred location during the hiring process.\n",
      "\n",
      "please note that the compensation details listed in us role postings reflect the base salary only, and do not include bonus, equity, or benefits. learn more about benefits at google. deliver exceptional software quality for one or more ips within silicon software. create and implement test strategies by working with development teams to identify risk areas and fill the testing gaps. drive test automation using existing test frameworks and work with the engineering productivity team to enhance and develop new test frameworks based on test requirements. manage product and engineering excellence as a core value within test engineering and with our associated development partners. triage and analyze test results and incoming feedback to identify areas for improvement.\n",
      "job_title: senior software test engineer, embedded systems, silicon\n",
      "has_salary_info: True\n",
      "num_responsibilities: 5\n"
     ]
    }
   ],
   "source": [
    "# Job features\n",
    "if hasattr(parsed_job, \"extract_features\"):\n",
    "    job_features = parsed_job.extract_features()\n",
    "    print(\"=== Job Features ===\")\n",
    "    for k, v in job_features.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "else:\n",
    "    print(\"JobDescription has no extract_features() method\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13aba0c8-0ef4-4f54-af98-0d28c7a80e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Resume Features ===\n",
      "years_experience: 1.9082819986310746\n",
      "num_previous_jobs: 4\n",
      "num_skills: 37\n",
      "num_projects: 3\n",
      "education_level: 0\n",
      "has_certifications: False\n",
      "skills_list: ['acr', 'aks', 'apache poi', 'aws', 'azure cloud', 'bitbucket', 'blob storage', 'c/c++', 'cosmos db', 'databricks', 'django', 'docker', 'firebase', 'gcp', 'git', 'github actions', 'go', 'hadoop', 'helm', 'java', 'jenkins', 'jira', 'junit', 'kafka', 'kubernetes', 'linux', 'maven', 'mongodb', 'mysql', 'neo4j', 'next.js', 'nodejs', 'python', 'redis', 'scala', 'spark', 'spring boot']\n",
      "skills_with_experience: ['acr', 'aks', 'alb', 'apache poi', 'aws', 'aws ec2', 'azure', 'azure cloud', 'bitbucket', 'blob storage', 'c/c++', 'cosmos db', 'databricks', 'django', 'docker', 'firebase', 'gcp', 'git', 'github actions', 'go', 'grpc', 'hadoop', 'helm', 'java', 'java servlets', 'jenkins', 'jira', 'junit', 'kafka', 'kubernetes', 'linux', 'maven', 'mongodb', 'mysql', 'neo4j', 'next.js', 'nodejs', 'postgresql', 'python', 'redis', 'scala', 'spark', 'spring boot']\n",
      "location_city: unknown\n",
      "location_country: unknown\n",
      "remote_preference: unknown\n",
      "experience_text: unknown built a real-time credit card operations dashboard (next.js, scala, postgresql) that improved fraud visibility and transaction monitoring, enabling 20+ internal stakeholders to track user states in real time. implemented a bulk email dispatch system with unc sink service over grpc, enabling secure communication with capacity for 50k+ daily emails directly from the admin dashboard developed a scala-based ato log monitoring tool analyzing millions of user events for anomalies; adopted by trust & security team (10+ analysts) to accelerate incident response by 30% created an on-chain wallet verification system in a 3-day hackathon, enabling gemini users to access decentralized apps with pre-verified identities; solution recognized internally for enhancing web3 security designed and implemented a java connector for ansys stk using stk connect api, integrating simulation workflows into enterprise systems and reducing integration time by 60% for 5+ teams developed 100+ junit test cases to validate crud operations and connector performance, improving code coverage by 35% and reducing integration defects reported in qa by 20% engineered siemens teamcenter plm connectors automating data ingestion from 5+ legacy systems, reducing manual mapping efforts by 70% and streamlining enterprise data migration created a vulnerability scanning utility (spring boot, apache poi, maven) parsing 200+ plugin dependencies daily, generating automated excel reports and reducing manual scanning effort by 80% collaborated with senior engineers to integrate the utility into devsecops pipelines, enabling early detection of 50+ critical vulnerabilities per release cycle and strengthening product security posture led migration of a stock market analysis mlops platform from aws to azure, deploying 6 microservices via aks, acr, cosmos db, and blob storage, improving scalability and cutting infra costs by 25% built ci/cd pipelines with github actions and automated container executions via cron jobs aligned with stock market trading hours, ensuring 99.9% uptime for real-time analytics workloads designed and deployed a scalable ai-powered recommendation system integrating content-based and collaborative ml models, achieving significant gains in recommendation precision through hybrid model optimization.\n",
      "built distributed data pipelines and caching infrastructure using kafka, mysql, and redis to support real-time ingestion, storage, and low-latency inference, mirroring production-scale cloud ai architectures.\n",
      "containerized and deployed the service on aws ec2 with modular apis, enabling fault-tolerant model serving, efficient resource utilization, and automated retraining workflows for continuous learning. unknown architected and deployed a cost-optimized microservices platform on aws with 3 core services (blockchain validator, qr auth, twitter recommender) in go/scala/grpc, sustaining 80k+ rps within a strict $1.28/hr budget, demonstrating scalability under real-world constraints\n",
      "processed 1tb+ twitter data using databricks spark etl and optimized amazon aurora mysql schema, enabling real-time recommendations with query latency reduced by 40%\n",
      "designed fault-tolerant infrastructure with alb, kubernetes managed node groups, and helm ci/cd pipelines, enabling auto-scaling to 1m+ concurrent requests with minimal latency and 99.99% uptime under peak load unknown engineered a full-stack social network prototype supporting reddit-style comment timelines using a polyglot backend architecture: mysql (relational), neo4j (graph), mongodb (document), and redis (key-value)\n",
      "designed custom schemas and implemented 4 concurrent query types via java servlets, reducing query response times by 35% for friend-of-friend and comment search operations\n",
      "optimized mongodb indexing and redis data structures (hashes/lists), benchmarking performance across 1.4m+ reddit records to achieve sub-50ms query latency for real-time social feeds unknown\n",
      "summary: unknown\n",
      "completeness: 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "# Resume features\n",
    "if hasattr(parsed_resume, \"extract_features\"):\n",
    "    resume_features = parsed_resume.extract_features()\n",
    "    print(\"\\n=== Resume Features ===\")\n",
    "    for k, v in resume_features.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "else:\n",
    "    print(\"Resume has no extract_features() method\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c7c18d-ff68-49d7-a0c4-c8b030851682",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e667ca8b-2fee-4741-88c4-63674674c592",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfuzz import fuzz\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "SKILL_SYNONYMS = {\n",
    "    \"ml\": \"machine learning\",\n",
    "    \"py\": \"python\",\n",
    "    \"js\": \"javascript\",\n",
    "    \"nodejs\": \"node.js\",\n",
    "    \"pytorch\": \"pytorch\",\n",
    "    \"tensorflow\": \"tensorflow\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15fc1415-6c46-4993-bc7a-f2f7edf04068",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_skill(s):\n",
    "    if not s:\n",
    "        return \"\"\n",
    "    s = s.lower().strip()\n",
    "    s = SKILL_SYNONYMS.get(s, s)\n",
    "    return \" \".join(s.split())\n",
    "\n",
    "\n",
    "def get_job_skills(parsed_job):\n",
    "    must = [normalize_skill(s) for s in parsed_job.required_skills.must_have]\n",
    "    nice = [normalize_skill(s) for s in parsed_job.required_skills.nice_to_have]\n",
    "    return must, nice\n",
    "\n",
    "\n",
    "def get_resume_skills(parsed_resume):\n",
    "    tech = parsed_resume.skills.technical\n",
    "    groups = [\n",
    "        tech.programming_languages,\n",
    "        tech.frameworks,\n",
    "        tech.databases,\n",
    "        tech.cloud,\n",
    "        tech.tools\n",
    "    ]\n",
    "\n",
    "    all_skills = []\n",
    "    for group in groups:\n",
    "        for skill in group:\n",
    "            all_skills.append(normalize_skill(skill.name))\n",
    "\n",
    "    return all_skills\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b66c901-4cff-4a49-b5cd-2fea73496301",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_skills_module(job_must, job_nice, cand_skills):\n",
    "    job_set = set(job_must)\n",
    "    cand_set = set(cand_skills)\n",
    "\n",
    "    # Exact match\n",
    "    exact_matches = job_set & cand_set\n",
    "\n",
    "    # Fuzzy match (remaining required)\n",
    "    remaining = job_set - exact_matches\n",
    "    fuzzy_matches = set()\n",
    "\n",
    "    for req in remaining:\n",
    "        for cand in cand_set:\n",
    "            if fuzz.token_sort_ratio(req, cand) >= 90:\n",
    "                fuzzy_matches.add(req)\n",
    "                break\n",
    "\n",
    "    matched_total = len(exact_matches | fuzzy_matches)\n",
    "    coverage = matched_total / len(job_set) if job_set else 0\n",
    "\n",
    "    base_score = coverage * 100\n",
    "\n",
    "    # Bonus from nice-to-have skills\n",
    "    nice_matches = len(set(job_nice) & cand_set)\n",
    "    bonus = min(nice_matches * 2, 10)\n",
    "\n",
    "    final = min(base_score + bonus, 100)\n",
    "\n",
    "    return {\n",
    "        \"score\": final,\n",
    "        \"base_score\": base_score,\n",
    "        \"bonus\": bonus,\n",
    "        \"matched\": matched_total,\n",
    "        \"required_total\": len(job_set),\n",
    "        \"nice_matches\": nice_matches\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0fcfd275-230d-4d53-9384-15282550d7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_required_years(text):\n",
    "    if text is None:\n",
    "        return 0\n",
    "    if isinstance(text, (int, float)):\n",
    "        return float(text)\n",
    "    t = text.lower()\n",
    "\n",
    "    m_range = re.search(r\"(\\d+)\\s*-\\s*(\\d+)\", t)\n",
    "    if m_range:\n",
    "        return (float(m_range.group(1)) + float(m_range.group(2))) / 2\n",
    "\n",
    "    m_single = re.search(r\"(\\d+)\", t)\n",
    "    if m_single:\n",
    "        return float(m_single.group(1))\n",
    "\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f227ba42-93ca-4a12-8a53-3c7c5ab38147",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_date(d):\n",
    "    try:\n",
    "        return datetime.strptime(d, \"%B %Y\")\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def compute_candidate_years(parsed_resume):\n",
    "    total_days = 0\n",
    "    now = datetime.now()\n",
    "\n",
    "    for exp in parsed_resume.experience:\n",
    "        start = parse_date(exp.dates.start)\n",
    "        end = parse_date(exp.dates.end)\n",
    "        if start is None:\n",
    "            continue\n",
    "        if end is None:\n",
    "            end = now\n",
    "        total_days += (end - start).days\n",
    "\n",
    "    return round(total_days / 365.25, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d720697b-9383-4cca-8d31-ac2fae066f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_experience_module(required_years, candidate_years):\n",
    "    if required_years == 0:\n",
    "        return {\"score\": 0, \"status\": \"no_requirement\"}\n",
    "\n",
    "    if candidate_years >= required_years * 2:\n",
    "        return {\"score\": 90, \"status\": \"overqualified\"}\n",
    "\n",
    "    if candidate_years >= required_years:\n",
    "        return {\"score\": 100, \"status\": \"meets\"}\n",
    "\n",
    "    return {\n",
    "        \"score\": (candidate_years / required_years) * 100,\n",
    "        \"status\": \"below\"\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a68255f8-f6f1-46ad-9ea0-50c99de21071",
   "metadata": {},
   "outputs": [],
   "source": [
    "EDU_LEVEL = {\n",
    "    \"high school\": 1,\n",
    "    \"diploma\": 1,\n",
    "    \"associate\": 2,\n",
    "    \"bachelor\": 3,\n",
    "    \"b.tech\": 3,\n",
    "    \"b.e\": 3,\n",
    "    \"b.s\": 3,\n",
    "    \"master\": 4,\n",
    "    \"m.tech\": 4,\n",
    "    \"m.e\": 4,\n",
    "    \"m.s\": 4,\n",
    "    \"mba\": 4,\n",
    "    \"phd\": 5,\n",
    "    \"doctor\": 5\n",
    "}\n",
    "\n",
    "def edu_level(s):\n",
    "    if isinstance(s, int):\n",
    "        return s\n",
    "    if not s:\n",
    "        return 0\n",
    "    s = s.lower()\n",
    "    for k, v in EDU_LEVEL.items():\n",
    "        if k in s:\n",
    "            return v\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0e3a94d-9dae-4997-abae-4a2d6777f79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_candidate_edu_level(parsed_resume):\n",
    "    best = 0\n",
    "    for edu in parsed_resume.education:\n",
    "        lvl = edu_level(edu.degree.level)\n",
    "        best = max(best, lvl)\n",
    "    return best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a57e8591-8951-436c-9ba4-523c66230f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_education_module(job_level_raw, cand_level_raw):\n",
    "    job_lvl = edu_level(job_level_raw)\n",
    "    cand_lvl = edu_level(cand_level_raw)\n",
    "\n",
    "    if cand_lvl >= job_lvl:\n",
    "        return {\"score\": 100, \"status\": \"meets\"}\n",
    "\n",
    "    if cand_lvl == job_lvl - 1:\n",
    "        return {\"score\": 75, \"status\": \"slightly below\"}\n",
    "\n",
    "    return {\"score\": 50, \"status\": \"significant_gap\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9179a24-c7f6-49e7-a97f-58e568b3ca69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_location_module(job_loc, cand_city, cand_country, remote_allowed):\n",
    "    job_loc = job_loc.lower()\n",
    "    city = cand_city.lower()\n",
    "    country = cand_country.lower()\n",
    "\n",
    "    if remote_allowed and cand_city == \"remote\":\n",
    "        return {\"score\": 100, \"status\": \"remote\"}\n",
    "\n",
    "    if city in job_loc:\n",
    "        return {\"score\": 100, \"status\": \"same_city\"}\n",
    "\n",
    "    if country in job_loc:\n",
    "        return {\"score\": 50, \"status\": \"same_country\"}\n",
    "\n",
    "    return {\"score\": 0, \"status\": \"relocation_needed\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "edbc291b-6df8-43f7-8dcf-9f027d9ee135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_all(parsed_job, parsed_resume):\n",
    "    # Skills\n",
    "    must, nice = get_job_skills(parsed_job)\n",
    "    cand_sk = get_resume_skills(parsed_resume)\n",
    "    skills = score_skills_module(must, nice, cand_sk)\n",
    "\n",
    "    # Experience\n",
    "    req_years = parsed_job.required_experience.min_years\n",
    "    cand_years = compute_candidate_years(parsed_resume)\n",
    "    exp = score_experience_module(req_years, cand_years)\n",
    "\n",
    "    # Education\n",
    "    job_edu = parsed_job.education_requirement.min_level\n",
    "    cand_edu = get_candidate_edu_level(parsed_resume)\n",
    "    education = score_education_module(job_edu, cand_edu)\n",
    "\n",
    "    # Location\n",
    "    job_loc = parsed_job.location_requirement.location\n",
    "    remote_allowed = parsed_job.location_requirement.remote_allowed\n",
    "    cand_city = parsed_resume.personal_info.location.city\n",
    "    cand_country = parsed_resume.personal_info.location.country\n",
    "    location = score_location_module(job_loc, cand_city, cand_country, remote_allowed)\n",
    "\n",
    "    # Weighted total\n",
    "    total = (\n",
    "        skills[\"score\"] * 0.30 +\n",
    "        exp[\"score\"]    * 0.25 +\n",
    "        education[\"score\"] * 0.15 +\n",
    "        location[\"score\"]  * 0.05\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"total_score\": round(total, 2),\n",
    "        \"skills\": skills,\n",
    "        \"experience\": exp,\n",
    "        \"education\": education,\n",
    "        \"location\": location\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f9d59d4c-0ded-4a62-afab-444bb73f7a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_score': 26.35,\n",
       " 'skills': {'score': 6.0,\n",
       "  'base_score': 0.0,\n",
       "  'bonus': 6,\n",
       "  'matched': 0,\n",
       "  'required_total': 15,\n",
       "  'nice_matches': 3},\n",
       " 'experience': {'score': 38.2, 'status': 'below'},\n",
       " 'education': {'score': 100, 'status': 'meets'},\n",
       " 'location': {'score': 0, 'status': 'relocation_needed'}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = score_all(parsed_job, parsed_resume)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319019ae-1891-40be-a9dc-75e5ae644392",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b76d50-49f1-40e6-82f3-057e121364ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f85f8390-73f7-4354-b420-486bb921d753",
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_score_all(parsed_job, parsed_resume):\n",
    "    print(\"\\n==============================\")\n",
    "    print(\"STEP 1 — Extract Job & Resume Skills\")\n",
    "    print(\"==============================\")\n",
    "    must_skills, nice_skills = get_job_skills(parsed_job)\n",
    "    cand_skills = get_resume_skills(parsed_resume)\n",
    "    print(\"Job MUST skills:\", must_skills)\n",
    "    print(\"Job NICE skills:\", nice_skills)\n",
    "    print(\"Candidate skills:\", cand_skills)\n",
    "\n",
    "    print(\"\\n==============================\")\n",
    "    print(\"STEP 2 — Skills Matching\")\n",
    "    print(\"==============================\")\n",
    "    skills_result = score_skills_module(must_skills, nice_skills, cand_skills)\n",
    "    print(\"→ Skills Result:\", skills_result)\n",
    "\n",
    "    print(\"\\n==============================\")\n",
    "    print(\"STEP 3 — Experience Matching\")\n",
    "    print(\"==============================\")\n",
    "    required_years = parsed_job.required_experience.min_years\n",
    "    candidate_years = compute_candidate_years(parsed_resume)\n",
    "    print(\"Required years:\", required_years)\n",
    "    print(\"Candidate years:\", candidate_years)\n",
    "\n",
    "    exp_result = score_experience_module(required_years, candidate_years)\n",
    "    print(\"→ Experience Result:\", exp_result)\n",
    "\n",
    "    print(\"\\n==============================\")\n",
    "    print(\"STEP 4 — Education Matching\")\n",
    "    print(\"==============================\")\n",
    "    job_edu = parsed_job.education_requirement.min_level\n",
    "    cand_edu = get_candidate_edu_level(parsed_resume)\n",
    "\n",
    "    print(\"Job required education:\", job_edu)\n",
    "    print(\"Candidate highest education:\", cand_edu)\n",
    "\n",
    "    edu_result = score_education_module(job_edu, cand_edu)\n",
    "    print(\"→ Education Result:\", edu_result)\n",
    "\n",
    "    print(\"\\n==============================\")\n",
    "    print(\"STEP 5 — Location Matching\")\n",
    "    print(\"==============================\")\n",
    "    job_loc = parsed_job.location_requirement.location\n",
    "    remote_allowed = parsed_job.location_requirement.remote_allowed\n",
    "    cand_city = parsed_resume.personal_info.location.city\n",
    "    cand_country = parsed_resume.personal_info.location.country\n",
    "\n",
    "    print(\"Job location:\", job_loc)\n",
    "    print(\"Candidate city:\", cand_city)\n",
    "    print(\"Candidate country:\", cand_country)\n",
    "    print(\"Remote allowed:\", remote_allowed)\n",
    "\n",
    "    loc_result = score_location_module(job_loc, cand_city, cand_country, remote_allowed)\n",
    "    print(\"→ Location Result:\", loc_result)\n",
    "\n",
    "    print(\"\\n==============================\")\n",
    "    print(\"STEP 6 — Final Weighted Score\")\n",
    "    print(\"==============================\")\n",
    "    final_score = (\n",
    "        skills_result[\"score\"] * 0.30 +\n",
    "        exp_result[\"score\"]    * 0.25 +\n",
    "        edu_result[\"score\"]    * 0.15 +\n",
    "        loc_result[\"score\"]    * 0.05\n",
    "    )\n",
    "    print(\"Weighted Total Score:\", final_score)\n",
    "\n",
    "    return {\n",
    "        \"total_score\": round(final_score, 2),\n",
    "        \"skills\": skills_result,\n",
    "        \"experience\": exp_result,\n",
    "        \"education\": edu_result,\n",
    "        \"location\": loc_result\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a550d258-41bb-49e8-86e9-03446a3fa38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "STEP 1 — Extract Job & Resume Skills\n",
      "==============================\n",
      "Job MUST skills: ['coding', 'developing test methodologies', 'writing test plans', 'creating test cases', 'debugging', 'hardware testing', 'embedded testing', 'automation', 'testing embedded software on soc on linux', 'testing embedded software on soc on android', 'testing embedded software on soc on real-time operating system (rtos)', 'hardware architecture', 'board schematics', 'protocols', 'standards']\n",
      "Job NICE skills: ['working with prototype devices', 'android application development', 'linux kernel driver test automation', 'framework development', 'java', 'c/c++', 'jni', 'python', 'test engineering', 'well tested code']\n",
      "Candidate skills: ['java', 'c/c++', 'python', 'go', 'scala', 'maven', 'spring boot', 'django', 'node.js', 'next.js', 'mysql', 'firebase', 'cosmos db', 'mongodb', 'azure cloud', 'aws', 'gcp', 'git', 'bitbucket', 'jira', 'jenkins', 'kubernetes', 'docker', 'hadoop', 'spark', 'linux', 'apache poi', 'junit', 'github actions', 'aks', 'acr', 'blob storage', 'kafka', 'redis', 'databricks', 'helm', 'neo4j']\n",
      "\n",
      "==============================\n",
      "STEP 2 — Skills Matching\n",
      "==============================\n",
      "→ Skills Result: {'score': 6.0, 'base_score': 0.0, 'bonus': 6, 'matched': 0, 'required_total': 15, 'nice_matches': 3}\n",
      "\n",
      "==============================\n",
      "STEP 3 — Experience Matching\n",
      "==============================\n",
      "Required years: 5.0\n",
      "Candidate years: 1.91\n",
      "→ Experience Result: {'score': 38.2, 'status': 'below'}\n",
      "\n",
      "==============================\n",
      "STEP 4 — Education Matching\n",
      "==============================\n",
      "Job required education: bachelor\n",
      "Candidate highest education: 4\n",
      "→ Education Result: {'score': 100, 'status': 'meets'}\n",
      "\n",
      "==============================\n",
      "STEP 5 — Location Matching\n",
      "==============================\n",
      "Job location: mountain view, ca, usa\n",
      "Candidate city: unknown\n",
      "Candidate country: unknown\n",
      "Remote allowed: False\n",
      "→ Location Result: {'score': 0, 'status': 'relocation_needed'}\n",
      "\n",
      "==============================\n",
      "STEP 6 — Final Weighted Score\n",
      "==============================\n",
      "Weighted Total Score: 26.35\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total_score': 26.35,\n",
       " 'skills': {'score': 6.0,\n",
       "  'base_score': 0.0,\n",
       "  'bonus': 6,\n",
       "  'matched': 0,\n",
       "  'required_total': 15,\n",
       "  'nice_matches': 3},\n",
       " 'experience': {'score': 38.2, 'status': 'below'},\n",
       " 'education': {'score': 100, 'status': 'meets'},\n",
       " 'location': {'score': 0, 'status': 'relocation_needed'}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = debug_score_all(parsed_job, parsed_resume)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b9ea2f-b3e5-41de-a96d-88c68a65cdfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "wbpeleixov",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/Shared/Main/CMU/Assignments/Intro to AI/ResumeAi\n",
      "✓ Successfully imported JobParser and ResumeParser!\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Set project root to parent directory of notebooks/\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "print(\"Project root:\", PROJECT_ROOT)\n",
    "\n",
    "# Make sure src/ is importable\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from src.parsers.job_parser import JobParser\n",
    "from src.parsers.resume_parser import ResumeParser\n",
    "\n",
    "print(\"✓ Successfully imported JobParser and ResumeParser!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18571fd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
